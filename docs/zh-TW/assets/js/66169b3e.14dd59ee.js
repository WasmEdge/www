"use strict";(self.webpackChunkbook=self.webpackChunkbook||[]).push([[3217],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),d=r,h=c["".concat(l,".").concat(d)]||c[d]||m[d]||o;return n?a.createElement(h,i(i({ref:t},u),{},{components:n})):a.createElement(h,i({ref:t},u))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},74547:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=n(87462),r=(n(67294),n(3905));const o={sidebar_position:2},i="PyTorch Backend",s={unversionedId:"develop/rust/wasinn/pytorch",id:"develop/rust/wasinn/pytorch",title:"PyTorch Backend",description:"We will use this example project to show how to make AI inference with a PyTorch model in WasmEdge and Rust.",source:"@site/docs/develop/rust/wasinn/pytorch.md",sourceDirName:"develop/rust/wasinn",slug:"/develop/rust/wasinn/pytorch",permalink:"/docs/zh-TW/develop/rust/wasinn/pytorch",draft:!1,editUrl:"https://github.com/wasmedge/docs/blob/main/docs/develop/rust/wasinn/pytorch.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"developSidebar",previous:{title:"Mediapipe solutions",permalink:"/docs/zh-TW/develop/rust/wasinn/mediapipe"},next:{title:"TensorFlow Lite Backend",permalink:"/docs/zh-TW/develop/rust/wasinn/tensorflow_lite"}},l={},p=[{value:"Prerequisite",id:"prerequisite",level:2},{value:"Quick start",id:"quick-start",level:2},{value:"Build and run",id:"build-and-run",level:2},{value:"Improve performance",id:"improve-performance",level:2},{value:"Understand the code",id:"understand-the-code",level:2}],u={toc:p},c="wrapper";function m(e){let{components:t,...n}=e;return(0,r.kt)(c,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"pytorch-backend"},"PyTorch Backend"),(0,r.kt)("p",null,"We will use ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/second-state/WasmEdge-WASINN-examples/tree/master/pytorch-mobilenet-image"},"this example project")," to show how to make AI inference with a PyTorch model in WasmEdge and Rust."),(0,r.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,r.kt)("p",null,"Besides the ",(0,r.kt)("a",{parentName:"p",href:"/docs/zh-TW/develop/rust/setup"},"regular WasmEdge and Rust requirements"),", please make sure that you have the ",(0,r.kt)("a",{parentName:"p",href:"/docs/zh-TW/start/install#wasi-nn-plug-in-with-pytorch-backend"},"Wasi-NN plugin with PyTorch installed"),"."),(0,r.kt)("h2",{id:"quick-start"},"Quick start"),(0,r.kt)("p",null,"Because the example already includes a compiled WASM file from the Rust code, we could use WasmEdge CLI to execute the example directly. First, git clone the ",(0,r.kt)("inlineCode",{parentName:"p"},"WasmEdge-WASINN-examples")," repo."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/second-state/WasmEdge-WASINN-examples.git\ncd WasmEdge-WASINN-examples/pytorch-mobilenet-image/\n")),(0,r.kt)("p",null,"Run the inference application in WasmEdge."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wasmedge --dir .:. wasmedge-wasinn-example-mobilenet-image.wasm mobilenet.pt input.jpg\n")),(0,r.kt)("p",null,"If everything goes well, you should have the terminal output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"Read torchscript binaries, size in bytes: 14376924\nLoaded graph into wasi-nn with ID: 0\nCreated wasi-nn execution context with ID: 0\nRead input tensor, size in bytes: 602112\nExecuted graph inference\n   1.) [954](20.6681)banana\n   2.) [940](12.1483)spaghetti squash\n   3.) [951](11.5748)lemon\n   4.) [950](10.4899)orange\n   5.) [953](9.4834)pineapple, ananas\n")),(0,r.kt)("h2",{id:"build-and-run"},"Build and run"),(0,r.kt)("p",null,"Let's build the wasm file from the rust source code. First, git clone the ",(0,r.kt)("inlineCode",{parentName:"p"},"WasmEdge-WASINN-examples")," repo."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/second-state/WasmEdge-WASINN-examples.git\ncd WasmEdge-WASINN-examples/pytorch-mobilenet-image/rust\n")),(0,r.kt)("p",null,"Second, use ",(0,r.kt)("inlineCode",{parentName:"p"},"cargo")," to build the example project."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cargo build --target wasm32-wasi --release\n")),(0,r.kt)("p",null,"The output WASM file is ",(0,r.kt)("inlineCode",{parentName:"p"},"target/wasm32-wasi/release/wasmedge-wasinn-example-mobilenet-image.wasm"),". Next, use WasmEdge to load the PyTorch model and then use it to classify objects in your image."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wasmedge --dir .:. wasmedge-wasinn-example-mobilenet-image.wasm mobilenet.pt input.jpg\n")),(0,r.kt)("p",null,"You can replace ",(0,r.kt)("inlineCode",{parentName:"p"},"input.jpg")," with your image file."),(0,r.kt)("h2",{id:"improve-performance"},"Improve performance"),(0,r.kt)("p",null,"You can make the inference program run faster by AOT compiling the ",(0,r.kt)("inlineCode",{parentName:"p"},"wasm")," file first."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wasmedge compile wasmedge-wasinn-example-mobilenet.wasm out.wasm\nwasmedge --dir .:. out.wasm mobilenet.pt input.jpg\n")),(0,r.kt)("h2",{id:"understand-the-code"},"Understand the code"),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/second-state/WasmEdge-WASINN-examples/tree/master/pytorch-mobilenet-image/rust/src/main.rs"},"main.rs")," is the complete example Rust source. First, read the image file and PyTorch model file names from the command line. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"let args: Vec<String> = env::args().collect();\nlet model_bin_name: &str = &args[1]; // File name for the PyTorch model\nlet image_name: &str = &args[2]; // File name for the input image\n")),(0,r.kt)("p",null,"We use a helper function called ",(0,r.kt)("inlineCode",{parentName:"p"},"image_to_tensor()")," to convert the input image into tensor data (the tensor type is ",(0,r.kt)("inlineCode",{parentName:"p"},"F32"),"). Now we can load the model, feed the tensor array from the image to the model, and get the inference output tensor array."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"// load model\nlet graph = wasi_nn::GraphBuilder::new(\n    wasi_nn::GraphEncoding::Pytorch,\n    wasi_nn::ExecutionTarget::CPU,\n).build_from_files([model_bin_name]).unwrap();\nlet mut context = graph.init_execution_context().unwrap();\n\n// Load a tensor that precisely matches the graph input tensor\nlet tensor_data = image_to_tensor(image_name.to_string(), 224, 224);\ncontext.set_input(0, wasi_nn::TensorType::F32, &[1, 3, 224, 224], &tensor_data).unwrap();\n\n// Execute the inference.\ncontext.compute().unwrap();\n\n// Retrieve the output.\nlet mut output_buffer = vec![0f32; 1000];\ncontext.get_output(0, &mut output_buffer).unwrap();\n")),(0,r.kt)("p",null,"In the above code, ",(0,r.kt)("inlineCode",{parentName:"p"},"wasi_nn::GraphEncoding::Pytorch")," means using the PyTorch backend, and ",(0,r.kt)("inlineCode",{parentName:"p"},"wasi_nn::ExecutionTarget::CPU")," means running the computation on the CPU. Finally, we sort the output and then print the top-5 classification results."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},'let results = sort_results(&output_buffer);\nfor i in 0..5 {\n  println!(\n    "   {}.) [{}]({:.4}){}",\n    i + 1,\n    results[i].0,\n    results[i].1,\n    imagenet_classes::IMAGENET_CLASSES[results[i].0]\n  );\n}\n')))}m.isMDXComponent=!0}}]);