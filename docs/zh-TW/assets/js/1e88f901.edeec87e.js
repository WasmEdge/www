"use strict";(self.webpackChunkbook=self.webpackChunkbook||[]).push([[6147],{5294:e=>{e.exports=JSON.parse('{"title":"AI inference","description":"Create AI inference functions in Rust, and run them in WasmEdge. Complete inference functions for mediapipe model libraries. Pytorch, Tensorflow, Tensorflow Lite, and OpenVINO model formats are supported.","slug":"/category/ai-inference","permalink":"/docs/zh-TW/category/ai-inference","navigation":{"previous":{"title":"Socket server","permalink":"/docs/zh-TW/develop/rust/socket_networking/server"},"next":{"title":"LLM inference","permalink":"/docs/zh-TW/develop/rust/wasinn/llm_inference"}}}')}}]);