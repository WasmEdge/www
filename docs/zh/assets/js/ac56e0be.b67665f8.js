"use strict";(self.webpackChunkbook=self.webpackChunkbook||[]).push([[3924],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>g});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),u=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},p=function(e){var n=u(e.components);return a.createElement(l.Provider,{value:n},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=u(t),c=r,g=m["".concat(l,".").concat(c)]||m[c]||d[c]||o;return t?a.createElement(g,i(i({ref:n},p),{},{components:t})):a.createElement(g,i({ref:n},p))}));function g(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=c;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[m]="string"==typeof e?e:r,i[1]=s;for(var u=2;u<o;u++)i[u]=t[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},2444:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>u});var a=t(7462),r=(t(7294),t(3905));const o={sidebar_position:3},i="OpenVINO Backend",s={unversionedId:"develop/rust/wasinn/openvino",id:"develop/rust/wasinn/openvino",title:"OpenVINO Backend",description:"We will use this example project to show how to do AI inference with an OpenVINO model in WasmEdge and Rust.",source:"@site/i18n/zh/docusaurus-plugin-content-docs/current/develop/rust/wasinn/openvino.md",sourceDirName:"develop/rust/wasinn",slug:"/develop/rust/wasinn/openvino",permalink:"/docs/zh/develop/rust/wasinn/openvino",draft:!1,editUrl:"https://github.com/wasmedge/docs/blob/main/docs/develop/rust/wasinn/openvino.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"developSidebar",previous:{title:"TensorFlow-Lite Backend",permalink:"/docs/zh/develop/rust/wasinn/tensorflow_lite"},next:{title:"TensorFlow Interface",permalink:"/docs/zh/develop/rust/tensorflow"}},l={},u=[{value:"Prerequisite",id:"prerequisite",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Build and Run the example from Rust source code",id:"build-and-run-the-example-from-rust-source-code",level:2},{value:"Improve performance",id:"improve-performance",level:2},{value:"Understand the code",id:"understand-the-code",level:2},{value:"More Examples",id:"more-examples",level:2}],p={toc:u},m="wrapper";function d(e){let{components:n,...t}=e;return(0,r.kt)(m,(0,a.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"openvino-backend"},"OpenVINO Backend"),(0,r.kt)("p",null,"We will use ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/second-state/WasmEdge-WASINN-examples/tree/master/openvino-mobilenet-image"},"this example project")," to show how to do AI inference with an OpenVINO model in WasmEdge and Rust."),(0,r.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,r.kt)("p",null,"Besides the ",(0,r.kt)("a",{parentName:"p",href:"/docs/zh/develop/rust/setup"},"regular WasmEdge and Rust requirements"),", please make sure that you have the ",(0,r.kt)("a",{parentName:"p",href:"/docs/zh/start/install#wasi-nn-plug-in-with-openvino-backend"},"Wasi-NN plugin with TensorFlow Lite installed"),"."),(0,r.kt)("h2",{id:"quick-start"},"Quick Start"),(0,r.kt)("p",null,"Because the example already includes a compiled WASM file from the Rust code, we could use WasmEdge CLI to execute the example directly."),(0,r.kt)("p",null,"First, git clone the ",(0,r.kt)("inlineCode",{parentName:"p"},"WasmEdge-WASINN-examples"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/second-state/WasmEdge-WASINN-examples.git\ncd WasmEdge-WASINN-examples\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# download the fixture files (OpenVINO model files)\n./download_mobilenet.sh\nwasmedge --dir .:. wasmedge-wasinn-example-mobilenet-image.wasm mobilenet.xml mobilenet.bin input.jpg\n")),(0,r.kt)("p",null,"If everything goes well, you should have the terminal output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"Read graph XML, size in bytes: 143525\nRead graph weights, size in bytes: 13956476\nLoaded graph into wasi-nn with ID: 0\nCreated wasi-nn execution context with ID: 0\nRead input tensor, size in bytes: 602112\nExecuted graph inference\n   1.) [954](0.9789)banana\n   2.) [940](0.0074)spaghetti squash\n   3.) [951](0.0014)lemon\n   4.) [969](0.0005)eggnog\n   5.) [942](0.0005)butternut squash\n")),(0,r.kt)("h2",{id:"build-and-run-the-example-from-rust-source-code"},"Build and Run the example from Rust source code"),(0,r.kt)("p",null,"Let's build the wasm file from the rust source code."),(0,r.kt)("p",null,"First, git clone the ",(0,r.kt)("inlineCode",{parentName:"p"},"WasmEdge-WASINN-examples"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/second-state/WasmEdge-WASINN-examples.git\ncd openvino-mobilenet-image/rust/\n")),(0,r.kt)("p",null,"Second, use ",(0,r.kt)("inlineCode",{parentName:"p"},"cargo")," to build the template project."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cargo build --target wasm32-wasi --release\n")),(0,r.kt)("p",null,"The output WASM file lies in ",(0,r.kt)("inlineCode",{parentName:"p"},"target/wasm32-wasi/release/wasmedge-wasinn-example-mobilenet-image.wasm"),"."),(0,r.kt)("p",null,"Next, download the OpenVINO model files and use WasmEdge to classify your own images."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"./download_mobilenet.sh\nwasmedge --dir .:. wasmedge-wasinn-example-mobilenet-image.wasm mobilenet.xml mobilenet.bin input.jpg\n")),(0,r.kt)("p",null,"You can replace ",(0,r.kt)("inlineCode",{parentName:"p"},"input.jpg")," with your own image file."),(0,r.kt)("h2",{id:"improve-performance"},"Improve performance"),(0,r.kt)("p",null,"For the AOT mode which is much more quickly, you can compile the WASM first:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wasmedgec wasmedge-wasinn-example-mobilenet.wasm out.wasm\nwasmedge --dir .:. out.wasm mobilenet.xml mobilenet.bin input.jpg\n")),(0,r.kt)("h2",{id:"understand-the-code"},"Understand the code"),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/second-state/WasmEdge-WASINN-examples/tree/master/openvino-mobilenet-image/rust/src/main.rs"},"main.rs")," is the full example Rust source."),(0,r.kt)("p",null,"First, read the model description and weights into memory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"let args: Vec<String> = env::args().collect();\nlet model_xml_name: &str = &args[1]; // File name for the model xml\nlet model_bin_name: &str = &args[2]; // File name for the weights\nlet image_name: &str = &args[3]; // File name for the input image\n\nlet xml = fs::read_to_string(model_xml_name).unwrap();\nlet weights = fs::read(model_bin_name).unwrap();\n")),(0,r.kt)("p",null,"We should use a helper function to convert the input image into the tensor data (the tensor type is ",(0,r.kt)("inlineCode",{parentName:"p"},"F32"),"):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"fn image_to_tensor(path: String, height: u32, width: u32) -> Vec<u8> {\n  let pixels = Reader::open(path).unwrap().decode().unwrap();\n  let dyn_img: DynamicImage = pixels.resize_exact(width, height, image::imageops::Triangle);\n  let bgr_img = dyn_img.to_bgr8();\n  // Get an array of the pixel values\n  let raw_u8_arr: &[u8] = &bgr_img.as_raw()[..];\n  // Create an array to hold the f32 value of those pixels\n  let bytes_required = raw_u8_arr.len() * 4;\n  let mut u8_f32_arr: Vec<u8> = vec![0; bytes_required];\n\n  for i in 0..raw_u8_arr.len() {\n    // Read the number as a f32 and break it into u8 bytes\n    let u8_f32: f32 = raw_u8_arr[i] as f32;\n    let u8_bytes = u8_f32.to_ne_bytes();\n\n    for j in 0..4 {\n      u8_f32_arr[(i * 4) + j] = u8_bytes[j];\n    }\n  }\n  return u8_f32_arr;\n}\n")),(0,r.kt)("p",null,"And use this helper funcion to convert the input image:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"let tensor_data = image_to_tensor(image_name.to_string(), 224, 224);\n")),(0,r.kt)("p",null,"Now we can start our inference with WASI-NN:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},"// load model\nlet graph = unsafe {\n  wasi_nn::load(\n    &[&xml.into_bytes(), &weights],\n    wasi_nn::GRAPH_ENCODING_OPENVINO,\n    wasi_nn::EXECUTION_TARGET_CPU,\n  )\n  .unwrap()\n};\n// initialize the computation context\nlet context = unsafe { wasi_nn::init_execution_context(graph).unwrap() };\n// initialize the input tensor\nlet tensor = wasi_nn::Tensor {\n  dimensions: &[1, 3, 224, 224],\n  type_: wasi_nn::TENSOR_TYPE_F32,\n  data: &tensor_data,\n};\n// set_input\nunsafe {\n  wasi_nn::set_input(context, 0, tensor).unwrap();\n}\n// Execute the inference.\nunsafe {\n  wasi_nn::compute(context).unwrap();\n}\n// retrieve output\nlet mut output_buffer = vec![0f32; 1001];\nunsafe {\n  wasi_nn::get_output(\n    context,\n    0,\n    &mut output_buffer[..] as *mut [f32] as *mut u8,\n    (output_buffer.len() * 4).try_into().unwrap(),\n  )\n  .unwrap();\n}\n")),(0,r.kt)("p",null,"Where the ",(0,r.kt)("inlineCode",{parentName:"p"},"wasi_nn::GRAPH_ENCODING_OPENVINO")," means using the OpenVINO\u2122 backend, and ",(0,r.kt)("inlineCode",{parentName:"p"},"wasi_nn::EXECUTION_TARGET_CPU")," means running the computation on CPU."),(0,r.kt)("p",null,"Finally, we sort the output and then print the top-5 classification result:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-rust"},'let results = sort_results(&output_buffer);\nfor i in 0..5 {\n  println!(\n    "   {}.) [{}]({:.4}){}",\n    i + 1,\n    results[i].0,\n    results[i].1,\n    imagenet_classes::IMAGENET_CLASSES[results[i].0]\n  );\n}\n')),(0,r.kt)("h2",{id:"more-examples"},"More Examples"),(0,r.kt)("p",null,"There are also an example that ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/second-state/WasmEdge-WASINN-examples/tree/master/openvino-road-segmentation-adas/rust"},"using OpenVINO to do road segmentation ADAS"),". Welcome to give it a try. You are also welcome to contribute your own examples."))}d.isMDXComponent=!0}}]);